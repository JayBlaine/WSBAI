{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WSBAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayBlaine/WSBAI/blob/main/WSBAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSwJMdWluSex"
      },
      "source": [
        "Regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHeHu1uERD29"
      },
      "source": [
        "Code section for reading GMEs stock data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-hcxPujnnCi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas_datareader as web\n",
        "import datetime as dt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "import csv, math, os\n",
        "\n",
        "def main():\n",
        "    stonk = \"GME\"\n",
        "    start = dt.datetime(2021, 1, 1)\n",
        "    end = dt.datetime.today()\n",
        "\n",
        "    data = web.DataReader(stonk,'stooq', start, end).reset_index()\n",
        "    data.drop('High', 1, inplace=True)\n",
        "    data.drop('Low', 1, inplace=True)\n",
        "\n",
        "    data = data.to_csv(r'./stonkdata.csv', index=False, header=True)\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWdM3Pl_b6gG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEyY5U8DUgGM"
      },
      "source": [
        "# WSB data set read\n",
        "# DO NOT RUN AFTER LIVE SCRAPE STARTS\n",
        "# SERIOUSLY, YOU WILL RUIN DATASET ONCE LIVE SCRAPING BEGINS\n",
        "\n",
        "def gmeChecker(title, body):\n",
        "  gmeKeys = ['gme', 'gamestop', 'dfv', 'deep fucking value', 'citadel', 'ken griffin', 'keith', 'gill', 'roaring kitty', 'if he\\'s in', 'if hes in']\n",
        "  title = title.strip().lower()\n",
        "  body = body.strip().lower()\n",
        "  for key in gmeKeys:\n",
        "    # body and title\n",
        "    if key in title or key in body:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "def dateChecker(date1):\n",
        "  dtTemp = dt.datetime.strptime(date1, '%Y-%m-%d %H:%M:%S')\n",
        "  actDate = dtTemp.date()\n",
        "  return actDate\n",
        "\n",
        "dateStockData = []\n",
        "dateStockData = pd.read_csv('./stonkdata.csv', usecols=['Date', 'Open', 'Close'])\n",
        "newD = pd.DataFrame(dateStockData)\n",
        "newD = newD.iloc[::-1]\n",
        "lineCount = len(dateStockData)\n",
        "\n",
        "# date, reddit total posts, gme total posts, ratio of gme to total, \n",
        "# avg score of reddit posts, average score of gme posts, avg comments total, avg comments gme\n",
        "byDate = {}\n",
        "\n",
        "# https://www.kaggle.com/gpreda/reddit-wallstreetsbets-posts\n",
        "wsbDataframe = pd.read_csv(\"reddit_wsb.csv\")\n",
        "\n",
        "with open('reddit_wsb.csv') as csv_file: \n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    for row in csv_reader:\n",
        "      if line_count > 1:\n",
        "        tempTitle = row[0]\n",
        "        tempScore = row[1]\n",
        "        tempCommNum = row[4]\n",
        "        tempBody = row[6]\n",
        "        tempDate = row[7]\n",
        "        tempPass = [tempTitle, tempScore, tempCommNum, tempBody, tempDate]\n",
        "        date1 = dateChecker(tempDate)\n",
        "\n",
        "        if date1 not in byDate.keys():\n",
        "          byDate[date1] = []\n",
        "          byDate[date1].append(tempPass)\n",
        "        else:\n",
        "          byDate[date1].append(tempPass)\n",
        "      line_count+=1\n",
        "\n",
        "redditPrelim = []\n",
        "\n",
        "for key in byDate.keys():\n",
        "  if key.year < 2021: #Gets rid of rogue row at 9/2020\n",
        "      continue\n",
        "  i=0\n",
        "  gmeCnt = 0\n",
        "  gmeCommTotal = 0\n",
        "  gmeUpTotal = 0\n",
        "  while i < len(byDate[key]):\n",
        "    gmeCheck = gmeChecker(byDate[key][i][0], byDate[key][i][3])\n",
        "    if gmeCheck:\n",
        "      gmeCnt+=1\n",
        "      gmeCommTotal+=int(byDate[key][i][2])\n",
        "      gmeUpTotal+=int(byDate[key][i][1])\n",
        "    i+=1\n",
        "  if i > 0 and gmeCnt > 0: # both posts and gme posts\n",
        "    redditPrelim.append([key, i, gmeCnt, gmeCnt/i, gmeUpTotal/gmeCnt, gmeCommTotal/gmeCnt])\n",
        "  elif i > 0: # no gme posts\n",
        "    redditPrelim.append([key, i, gmeCnt, gmeCnt/i, 0, 0])\n",
        "  else: # no posts\n",
        "    continue\n",
        "\n",
        "# print(redditPrelim)\n",
        "columns = dateStockData.filter([\"Date\"]).values\n",
        "with open('wsb_clean.csv', mode='w') as write_file:\n",
        "    writer = csv.writer(write_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    i=0\n",
        "    date=0\n",
        "    #TODO\n",
        "    writer.writerow(['Date', 'open', 'close', 'total posts', 'GME count', '% GME', 'avg GME upvotes', 'avg GME comments'])\n",
        "    while i < len(redditPrelim):\n",
        "      if str(redditPrelim[i][0]) in columns:\n",
        "        writer.writerow([redditPrelim[i][0], dateStockData['Open'][date], dateStockData['Close'][date], redditPrelim[i][1], \n",
        "                         redditPrelim[i][2], redditPrelim[i][3], redditPrelim[i][4], redditPrelim[i][5]])\n",
        "        date+=1\n",
        "      i+=1\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3w25VE4GRpV"
      },
      "source": [
        "Break"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "68gMUp0j8wai",
        "outputId": "f2e42c07-8aa3-4d3d-ca22-d646a41e3d0c"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "testDataSize = 40\n",
        "fullFile = pd.read_csv(\"wsb_clean.csv\")\n",
        "\n",
        "# Load dataset.\n",
        "dftrain = fullFile.head(testDataSize) # training data\n",
        "dfeval = fullFile.iloc[testDataSize:] # testing data\n",
        "\n",
        "\n",
        "\n",
        "dftrain.pop('Date')\n",
        "dfeval.pop('Date')\n",
        "# dftrain.pop('diff')\n",
        "# dfeval.pop('diff')\n",
        "y_train = dftrain.pop('close')\n",
        "y_eval = dfeval.pop('close')\n",
        "#dftrain = dftrain.astype(np.float16)\n",
        "#dfeval = dfeval.astype(np.float16)\n",
        "\n",
        "dataCol = ['open', 'total posts', 'GME count', '% GME', 'avg GME upvotes', 'avg GME comments']\n",
        "\n",
        "feature_col = []\n",
        "\n",
        "for feature in dataCol:\n",
        "  feature_col.append(tf.feature_column.numeric_column(feature, dtype=tf.float32))\n",
        "\n",
        "# print(feature_columns)\n",
        "\n",
        "def make_input_fn(data, label, epochs=10, shuffle=True, batch=16):\n",
        "  def input_function():  # inner function, this will be returned\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data), label))  # create tf.data.Dataset object with data and its label\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)  # randomize order of data\n",
        "    ds = ds.batch(batch).repeat(epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    return ds  # return a batch of the dataset\n",
        "  return input_function  # return a function object for use\n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, epochs=1, shuffle=False)\n",
        "\n",
        "linear_est = tf.estimator.LinearRegressor(feature_columns=feature_col)\n",
        "\n",
        "linear_est.train(train_input_fn)  # train\n",
        "result = linear_est.evaluate(eval_input_fn)  # get model metrics/stats by testing on testing data\n",
        "\n",
        "clear_output()  # clears consoke output\n",
        "print(result)  # the result variable is simply a dict of stats about our model\n",
        "\n",
        "\n",
        "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
        "print(pred_dicts)\n",
        "print(len(pred_dicts))\n",
        "probs = pd.Series([pred['predictions'][0] for pred in pred_dicts])\n",
        "\n",
        "probs.plot(kind='hist', bins=20, title='predicted probabilities')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'average_loss': 9206.849, 'label/mean': 100.26714, 'loss': 9206.849, 'prediction/mean': 176.09305, 'global_step': 30}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp_gesk0re/model.ckpt-30\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "[{'predictions': array([128.11719], dtype=float32)}, {'predictions': array([113.85316], dtype=float32)}, {'predictions': array([171.08595], dtype=float32)}, {'predictions': array([146.5098], dtype=float32)}, {'predictions': array([179.08008], dtype=float32)}, {'predictions': array([217.74069], dtype=float32)}, {'predictions': array([106.51508], dtype=float32)}, {'predictions': array([124.81176], dtype=float32)}, {'predictions': array([102.52598], dtype=float32)}, {'predictions': array([209.85083], dtype=float32)}, {'predictions': array([223.35803], dtype=float32)}, {'predictions': array([231.7871], dtype=float32)}, {'predictions': array([248.3646], dtype=float32)}, {'predictions': array([261.70255], dtype=float32)}]\n",
            "14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fed36ec5090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqIZGgGFxK6C"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Make numpy values easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "print(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD4Xv_5Uyxpv"
      },
      "source": [
        "Creating Guess\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gum5IrJty1D2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223d7922-4c71-4242-b956-84f7ccac317e"
      },
      "source": [
        "daysToPredict = 20\n",
        "predictionLayers = 64\n",
        "\n",
        "# Open the stock data file\n",
        "stonkData = pd.read_csv('./stonkdata.csv') # format = Date, Open, Close, Volume\n",
        "\n",
        "# Reading only the closing prices\n",
        "# stonkWithDate = stonkData.filter(['Close'], ['Date'])\n",
        "stonkPrices = (stonkData.filter(['Close'])).values\n",
        "dataLength = len(stonkPrices)\n",
        "\n",
        "# If we only want to train half of the data\n",
        "#halfOfData = math.ceil(len(stonkPrices) * 0.5)\n",
        "\n",
        "# Scaling the data / Takes in the stock data and makes it into a number between 0 and 1\n",
        "dataScaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaledData = dataScaler.fit_transform(stonkPrices).reshape(-1,1)\n",
        "\n",
        "# Spliting up the data for x and y training\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "# Amount we wanted trained using the length of our data\n",
        "for x in range(daysToPredict, dataLength):\n",
        "  x_train.append(scaledData[x - daysToPredict:x, 0])\n",
        "  y_train.append(scaledData[x, 0])\n",
        "  if x <= daysToPredict:\n",
        "    print(f\"X data-----------------\\n{x_train}\\nY data-----------------\\n{y_train}\")\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(x_train)\n",
        "\n",
        "# x_train = np.reshape(x_train, dataLength, daysToPredict, 1)\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "\n",
        "print(x_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X data-----------------\n",
            "[array([0.45200751, 0.3746745 , 0.37497729, 0.42726942, 0.46330164,\n",
            "       0.48664688, 0.50641918, 0.51383758, 0.52746321, 0.52252771,\n",
            "       0.53657724, 0.49672985, 0.49582147, 0.50414825, 0.312148  ,\n",
            "       0.49809241, 0.53666808, 0.55416944, 0.55865076, 0.58305577])]\n",
            "Y data-----------------\n",
            "[0.5780899897050809]\n",
            "(50, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLytcMTYCjnN"
      },
      "source": [
        "Creating the training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4w_XWtYCi-F"
      },
      "source": [
        "# Building the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=predictionLayers, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "# Dropout randomly inputs 0s to help against overfitting (at a rate of 0.2)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMGqnw8jfA7V"
      },
      "source": [
        "graphStonks = pd.read_csv(\"./stonkdata.csv\")\n",
        "\n",
        "graphStonks.head()\n",
        "graphStonks['Close'].plot(label='GME', figsize=(16, 8), title='Adjusted Closing Price', color='red')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEp773okjI7B"
      },
      "source": [
        "Live Scrape code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE7ev55ji7l0"
      },
      "source": [
        "# REDDIT DATA SCRAPE\n",
        "#import asyncpraw\n",
        "#import nest_asyncio\n",
        "\n",
        "#async def main():\n",
        "#  reddit = asyncpraw.Reddit(client_id='ORNE1J4ncT_tGg', client_secret= 'sa-2SPPkOY-w_kMIBSeAostYFg804Q', user_agent='WSBAI:Python/urllib:v0.0.1 (by u/WSBAI_00123)', \n",
        "#                            username=\"WSBAI_00123\", password=\"lint$h@d0w,./\")\n",
        "#  wsb_sub = await reddit.subreddit('WallStreetBets')\n",
        "\n",
        "  \n",
        "#  i = 0\n",
        "#  print(reddit.read_only)\n",
        "#  posts = [] # posts that are good from keywords\n",
        "#  keywords = ['GME', 'gamestop', 'diamond', 'diamond hands', 'ape', 'apes']\n",
        "#  postIds = {}\n",
        "\n",
        "  # TODO: \n",
        "\n",
        "  # -Keyword list for relevant posts/comments\n",
        "  # -handle emojis\n",
        "  # -post id dictionary for posts already read through\n",
        "  # -possible CV of reddit posts if jpg/png\n",
        "  # -store into csv file\n",
        "\n",
        "#  async for submission in wsb_sub.new(limit=20):\n",
        "#    test = submission.downvote()\n",
        "    # submission.id\n",
        "    # submission.created_utc   CHECK FOR LESS THAN DAY OLD\n",
        "\n",
        "    # submission.title\n",
        "    # submission.num_comments\n",
        "    # submission.upvote_ratio\n",
        "    # submission.link_flair_text\n",
        "    # num text keywords\n",
        "    # num comment keywords\n",
        "\n",
        "\n",
        "    # submission.url           POSSIBLE IMG CHECKING\n",
        "    \n",
        "    # submission.score   ----MAY NOT NEED----\n",
        "    \n",
        "    \n",
        "    #---STUFF TO LOOP THROUGH TO COUNT NUM OF KEYWORDS--- comments, selftext\n",
        "    #submission.selftext\n",
        "    #comments = await submission.comments()\n",
        "    #for comment in comments:\n",
        "    #  print(comment.body)\n",
        "    #  print(comment.score)\n",
        "\n",
        "    #posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
        "  #posts = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
        "\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#  nest_asyncio.apply()\n",
        "#  loop = asyncio.get_event_loop() \n",
        "#  loop.run_until_complete(main())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}